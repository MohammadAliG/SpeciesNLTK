{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import requests\n",
    "from rake_nltk import Metric, Rake\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from transformers import pipeline\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxList = glob.glob(\"./CSV Files/*taxonomy.csv\")\n",
    "assList = glob.glob(\"./CSV Files/*assessments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftList = []\n",
    "for file in taxList:\n",
    "    dftList.append(pd.read_csv(file))\n",
    "dfaList = []\n",
    "for file in assList:\n",
    "    dfaList.append(pd.read_csv(file))\n",
    "    \n",
    "dfTotal = pd.concat(dftList)\n",
    "dfAssess = pd.concat(dfaList)\n",
    "dfAssess.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assessmentId</th>\n",
       "      <th>internalTaxonId</th>\n",
       "      <th>redlistCategory</th>\n",
       "      <th>yearPublished</th>\n",
       "      <th>populationTrend</th>\n",
       "      <th>systems</th>\n",
       "      <th>realm</th>\n",
       "      <th>yearLastSeen</th>\n",
       "      <th>scopes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>495907</td>\n",
       "      <td>10041</td>\n",
       "      <td>Critically Endangered</td>\n",
       "      <td>2021</td>\n",
       "      <td>Decreasing</td>\n",
       "      <td>Terrestrial|Freshwater (=Inland waters)</td>\n",
       "      <td>Indomalayan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>499158</td>\n",
       "      <td>10825</td>\n",
       "      <td>Critically Endangered</td>\n",
       "      <td>2021</td>\n",
       "      <td>Decreasing</td>\n",
       "      <td>Terrestrial</td>\n",
       "      <td>Australasian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>499618</td>\n",
       "      <td>10950</td>\n",
       "      <td>Critically Endangered</td>\n",
       "      <td>2021</td>\n",
       "      <td>Decreasing</td>\n",
       "      <td>Terrestrial|Freshwater (=Inland waters)</td>\n",
       "      <td>Indomalayan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>508210</td>\n",
       "      <td>12696</td>\n",
       "      <td>Critically Endangered</td>\n",
       "      <td>2019</td>\n",
       "      <td>Decreasing</td>\n",
       "      <td>Terrestrial</td>\n",
       "      <td>Afrotropical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>516369</td>\n",
       "      <td>135889</td>\n",
       "      <td>Critically Endangered</td>\n",
       "      <td>2020</td>\n",
       "      <td>Decreasing</td>\n",
       "      <td>Terrestrial|Freshwater (=Inland waters)</td>\n",
       "      <td>Neotropical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Global</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   assessmentId  internalTaxonId        redlistCategory  yearPublished  \\\n",
       "0        495907            10041  Critically Endangered           2021   \n",
       "1        499158            10825  Critically Endangered           2021   \n",
       "2        499618            10950  Critically Endangered           2021   \n",
       "3        508210            12696  Critically Endangered           2019   \n",
       "4        516369           135889  Critically Endangered           2020   \n",
       "\n",
       "  populationTrend                                  systems         realm  \\\n",
       "0      Decreasing  Terrestrial|Freshwater (=Inland waters)   Indomalayan   \n",
       "1      Decreasing                              Terrestrial  Australasian   \n",
       "2      Decreasing  Terrestrial|Freshwater (=Inland waters)   Indomalayan   \n",
       "3      Decreasing                              Terrestrial  Afrotropical   \n",
       "4      Decreasing  Terrestrial|Freshwater (=Inland waters)   Neotropical   \n",
       "\n",
       "  yearLastSeen  scopes  \n",
       "0          NaN  Global  \n",
       "1          NaN  Global  \n",
       "2          NaN  Global  \n",
       "3          NaN  Global  \n",
       "4          NaN  Global  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTotalClean = dfTotal[[\"internalTaxonId\", \"speciesName\", \"className\", \"familyName\", \"scientificName\"]]\n",
    "dfTotalClean.head()\n",
    "dfAssessClean = dfAssess[[\"assessmentId\", \"internalTaxonId\", \"redlistCategory\", \"yearPublished\", \"populationTrend\", \"systems\", \"realm\", \"yearLastSeen\", \"scopes\"]]\n",
    "dfAssessClean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAssessClean.to_csv(\"assessments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url = \"https://api.gbif.org/v1/species?language=EN&nameType=SCIENTIFIC&name=Heosemys annandalii\"\n",
    "results = requests.get(url).text\n",
    "uName = results[results.find(\"\\\"vernacularName\") : results.find(\",\\\"authorship\")]\n",
    "cName = uName[uName.find(\":\")+1:-1].replace(\"\\\"\", \"\")\n",
    "print(cName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dfTotalClean.iterrows():\n",
    "    url = \"https://api.gbif.org/v1/species?language=EN&nameType=SCIENTIFIC&name=\" + row['scientificName']\n",
    "    results = requests.get(url).text\n",
    "    uName = results[results.find(\"\\\"vernacularName\") : results.find(\",\\\"authorship\")]\n",
    "    cName = uName[uName.find(\":\")+1:-1].replace(\"\\\"\", \"\")\n",
    "    dfTotalClean.loc[index, \"commonName\"] = cName\n",
    "    time.sleep(.01)\n",
    "dfTotalClean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTotalClean.reset_index(inplace=True, drop=True)\n",
    "dfTotalClean.to_csv(\"species.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9129\n"
     ]
    }
   ],
   "source": [
    "allThreats = dfAssess['threats'].tolist()\n",
    "threats = []\n",
    "for x in allThreats:\n",
    "    threats.append(BeautifulSoup(str(x), 'html.parser').get_text().replace(\"(\", \"\").replace(\")\", \"\")) \n",
    "\n",
    "print(len(threats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Rake(punctuations=\"““’‘‘––().,;:></?'!@#$%^&*-_=+\")\n",
    "s.extract_keywords_from_text(\"\".join(threats))\n",
    "swordD = s.get_word_frequency_distribution()\n",
    "sworddf = pd.DataFrame.from_dict(swordD, orient='index')\n",
    "sworddf = sworddf.reset_index().rename(columns={'index':'word', 0:'count'})\n",
    "rworddf = sworddf[sworddf['count'] >= 10].sort_values(by=['count'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = classifier(rworddf.word.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = pd.DataFrame(results)\n",
    "rdf = pd.concat([rworddf, rdf], axis=1)\n",
    "nwDF = rdf[rdf['label'] == \"NEGATIVE\"].reset_index(drop=True)\n",
    "nwDF.to_csv(\"test4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.read_csv(\"test4.csv\")\n",
    "\n",
    "keywords = words[\"word\"].to_list()\n",
    "keywords.remove(\"p\")\n",
    "keywords.remove(\"f\")\n",
    "keywords.remove(\"threat\")\n",
    "keywords.remove(\"threats\")\n",
    "keywords.remove(\"threatened\")\n",
    "keywords.remove(\"threaten\")\n",
    "keywords.remove(\"0\")\n",
    "keywords.remove(\"comm\")\n",
    "keywords.append(\"Human\")\n",
    "keywords.append(\"human\")\n",
    "keywords.append(\"Deforestation\")\n",
    "keywords.append(\"deforestation\")\n",
    "keywords.append(\"Habitat loss\")\n",
    "keywords.append(\"habitat loss\")\n",
    "keywords.append(\"logging\")\n",
    "keywords.append(\"forest loss\")\n",
    "keywords.append(\"agriculture\")\n",
    "keywords.append(\"mining\")\n",
    "for x in range(2025):\n",
    "    if str(x) in keywords:\n",
    "        keywords.remove(str(x))\n",
    "for x in keywords:\n",
    "    if len(str(x)) < 3:\n",
    "        keywords.remove(x)\n",
    "\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1684: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = infer_fill_value(value)\n",
      "C:\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>internalTaxonId</th>\n",
       "      <th>threats</th>\n",
       "      <th>Threat Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10041</td>\n",
       "      <td>&lt;p&gt;The main threats to this species are harves...</td>\n",
       "      <td>loss, however, illegal, rat, viet, late, trade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10825</td>\n",
       "      <td>Current threats include severe and rampant hab...</td>\n",
       "      <td>logging, red, destruction, road, reduced, seve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10950</td>\n",
       "      <td>&lt;p&gt;Widespread local subsistence consumption of...</td>\n",
       "      <td>small, illegal, fragmented, dam, rat, erosion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12696</td>\n",
       "      <td>The single most serious human threat to &lt;em&gt;Ma...</td>\n",
       "      <td>small, degradation, illegal, red, predation, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135889</td>\n",
       "      <td>Local inhabitants' comments to I. De la Riva, ...</td>\n",
       "      <td>declines, although, decline, fungus, severe, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   internalTaxonId                                            threats  \\\n",
       "0            10041  <p>The main threats to this species are harves...   \n",
       "1            10825  Current threats include severe and rampant hab...   \n",
       "2            10950  <p>Widespread local subsistence consumption of...   \n",
       "3            12696  The single most serious human threat to <em>Ma...   \n",
       "4           135889  Local inhabitants' comments to I. De la Riva, ...   \n",
       "\n",
       "                                     Threat Keywords  \n",
       "0  loss, however, illegal, rat, viet, late, trade...  \n",
       "1  logging, red, destruction, road, reduced, seve...  \n",
       "2  small, illegal, fragmented, dam, rat, erosion,...  \n",
       "3  small, degradation, illegal, red, predation, d...  \n",
       "4  declines, although, decline, fungus, severe, c...  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfThreats = dfAssess[['internalTaxonId','threats']]\n",
    "\n",
    "for index, row in dfThreats.iterrows():\n",
    "    sL = \"\"\n",
    "    rowString = BeautifulSoup(str(row['threats']), 'html.parser').get_text().replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
    "    for word in keywords:\n",
    "        if word in rowString:\n",
    "            sL += word + \", \"\n",
    "    dfThreats.at[index, \"Threat Keywords\"] = sL\n",
    "dfThreats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfThreats.to_csv(\"threatTest2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r = Rake(max_length=2, punctuations=\"““’‘‘––().,;:></?'!@#$%^&*-_=+\")\n",
    "r.extract_keywords_from_sentences(threats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wordD = r.get_word_frequency_distribution()\n",
    "worddf = pd.DataFrame.from_dict(wordD, orient='index')\n",
    "worddf.to_csv(\"test2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g = Rake(include_repeated_phrases=False, punctuations=\"““’‘‘––().,;:></?'!@#$%^&*-_=+\")\n",
    "g.extract_keywords_from_text(\"\".join(threats))\n",
    "results2 = classifier(g.get_ranked_phrases())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r2df = pd.DataFrame(results)\n",
    "r2df = pd.concat([r2df, pd.Series(g.get_ranked_phrases())], axis=1)\n",
    "r2df = r2df[r2df['label'] == \"NEGATIVE\"].reset_index(drop=True)\n",
    "r2df.to_csv(\"test5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9129\n"
     ]
    }
   ],
   "source": [
    "allConserve = dfAssess['conservationActions'].tolist()\n",
    "conserve = []\n",
    "for x in allConserve:\n",
    "    conserve.append(BeautifulSoup(str(x), 'html.parser').get_text().replace(\"(\", \"\").replace(\")\", \"\")) \n",
    "\n",
    "print(len(conserve))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Rake(punctuations=\"““’‘‘––().,;:></?'!@#$%^&*-_=+\")\n",
    "c.extract_keywords_from_text(\"\".join(conserve))\n",
    "cwordD = c.get_word_frequency_distribution()\n",
    "cworddf = pd.DataFrame.from_dict(cwordD, orient='index')\n",
    "cworddf = cworddf.reset_index().rename(columns={'index':'word', 0:'count'})\n",
    "cworddf = cworddf[cworddf['count'] >= 10].sort_values(by=['count'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = classifier(cworddf.word.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = pd.DataFrame(results3)\n",
    "cdf = pd.concat([cworddf, cdf], axis=1)\n",
    "nwcDF = cdf[cdf['label'] == \"POSITIVE\"].reset_index(drop=True)\n",
    "nwcDF.to_csv(\"ctest1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwords = pd.read_csv(\"ctest1.csv\")\n",
    "\n",
    "ckeywords = cwords[\"word\"].to_list()\n",
    "ckeywords.remove(\"species\")\n",
    "ckeywords.remove(\"et\")\n",
    "ckeywords.remove(\"al\")\n",
    "ckeywords.remove(\"litt\")\n",
    "ckeywords.remove(\"pers\")\n",
    "ckeywords.remove(\"also\")\n",
    "ckeywords.remove(\"iii\")\n",
    "ckeywords.remove(\"://\")\n",
    "ckeywords.remove(\"nam\")\n",
    "ckeywords.remove(\"conservation\")\n",
    "ckeywords.remove(\"actions\")\n",
    "ckeywords.remove(\"appendix\")\n",
    "ckeywords.remove(\"cites\")\n",
    "ckeywords.remove(\"area\")\n",
    "ckeywords.remove(\"areas\")\n",
    "ckeywords.append(\"no conservation measures\")\n",
    "for x in range(2025):\n",
    "    if str(x) in ckeywords:\n",
    "        ckeywords.remove(str(x))\n",
    "for x in ckeywords:\n",
    "    if len(str(x)) < 3:\n",
    "        ckeywords.remove(x)\n",
    "print(ckeywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfConserve = dfAssess[['internalTaxonId','conservationActions']]\n",
    "\n",
    "for index, row in dfConserve.iterrows():\n",
    "    sL = \"\"\n",
    "    rowString = BeautifulSoup(str(row['conservationActions']), 'html.parser').get_text().replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
    "    for word in ckeywords:\n",
    "        if str(word) in rowString:\n",
    "            sL += str(word) + \", \"\n",
    "    dfConserve.at[index, \"Conserve Keywords\"] = sL\n",
    "dfConserve.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfConserve.to_csv(\"conserveTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHabitat = dfAssess[['internalTaxonId', 'habitat', 'systems']]\n",
    "cleanedRows = []\n",
    "for index, row in dfHabitat.iterrows():\n",
    "    rowString = BeautifulSoup(str(row['habitat']), 'html.parser').get_text().replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
    "    dfHabitat.at[index, \"habitat_type\"] = rowString[:rowString.find(\".\")+1]\n",
    "dfHabitat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHabitat.to_csv(\"habitatTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = []\n",
    "for x in threats[:5]:\n",
    "    wrdlen = len(x.split(\" \"))\n",
    "    summ += summarizer(x, max_length=wrdlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summL = []\n",
    "for x in summ:\n",
    "    summary = list(x.values())\n",
    "    summL.append(summary[0])\n",
    "print(summL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\RaininSwords-\n",
      "[nltk_data]     Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'genetics'"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humans = wordnet.synsets(\"human\")\n",
    "natural = wordnet.synsets(\"natural\")\n",
    "genetics = wordnet.synsets(\"genetics\")\n",
    "disease = wordnet.synsets(\"disease\")\n",
    "tcategoryList = [humans, natural, genetics, disease]\n",
    "str(genetics[0].lemmas()[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('pollution.n.01'), Synset('befoulment.n.01'), Synset('contamination.n.03')] [Synset('degradation.n.01'), Synset('abasement.n.01')]\n",
      "0.4484864121087031\n"
     ]
    }
   ],
   "source": [
    "first = wordnet.synsets(\"pollution\")\n",
    "second = wordnet.synsets(\"degradation\")\n",
    "print(first, second)\n",
    "\n",
    "avg = 0\n",
    "count = 0\n",
    "for x in first:\n",
    "    for y in second:\n",
    "        if y.wup_similarity(x) > .2:\n",
    "            avg += y.wup_similarity(x)\n",
    "            count += 1\n",
    "print(avg/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>internalTaxonId</th>\n",
       "      <th>Threat Keywords</th>\n",
       "      <th>Humans</th>\n",
       "      <th>Natural</th>\n",
       "      <th>Genes</th>\n",
       "      <th>Diseases</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10041</td>\n",
       "      <td>loss, however, illegal, rat, viet, late, trade...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10825</td>\n",
       "      <td>logging, red, destruction, road, reduced, seve...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10950</td>\n",
       "      <td>small, illegal, fragmented, dam, rat, erosion,...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12696</td>\n",
       "      <td>small, degradation, illegal, red, predation, d...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135889</td>\n",
       "      <td>declines, although, decline, fungus, severe, c...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>136773</td>\n",
       "      <td>loss, hunting, deforestation, although, red, l...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14765</td>\n",
       "      <td>mining, illegal, red, low, exploitation, trade...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15026</td>\n",
       "      <td>loss, degradation, low, pressure, exploitation...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15509</td>\n",
       "      <td>despite, traded, exported, pit, anti, habit, d...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15918</td>\n",
       "      <td>loss, red, affected, long, commercial, far, ca...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>163458</td>\n",
       "      <td>mining, illegal, sand, ill, mining,</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>164598</td>\n",
       "      <td>loss, past, lost, long, longer, dam, half, ars...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>164889</td>\n",
       "      <td>logging, small, decline, caused, severe, reser...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>135458600</td>\n",
       "      <td>loss, small, degradation, red, pollution, low,...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>170525</td>\n",
       "      <td>however, degradation, mining, long, south, lim...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17081</td>\n",
       "      <td>small, declines, decline, red, predation, dest...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>172524</td>\n",
       "      <td>loss, small, declines, although, decline, red,...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>173018</td>\n",
       "      <td>illegal, red, low, commercial, conditions, dam...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>174472</td>\n",
       "      <td>small, although, caused, red, invasive, severe...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>175363</td>\n",
       "      <td>pressure, restricted, degraded, heavily, cutti...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       internalTaxonId                                    Threat Keywords  \\\n",
       "Index                                                                       \n",
       "0                10041  loss, however, illegal, rat, viet, late, trade...   \n",
       "1                10825  logging, red, destruction, road, reduced, seve...   \n",
       "2                10950  small, illegal, fragmented, dam, rat, erosion,...   \n",
       "3                12696  small, degradation, illegal, red, predation, d...   \n",
       "4               135889  declines, although, decline, fungus, severe, c...   \n",
       "5               136773  loss, hunting, deforestation, although, red, l...   \n",
       "6                14765  mining, illegal, red, low, exploitation, trade...   \n",
       "7                15026  loss, degradation, low, pressure, exploitation...   \n",
       "8                15509  despite, traded, exported, pit, anti, habit, d...   \n",
       "9                15918  loss, red, affected, long, commercial, far, ca...   \n",
       "10              163458               mining, illegal, sand, ill, mining,    \n",
       "11              164598  loss, past, lost, long, longer, dam, half, ars...   \n",
       "12              164889  logging, small, decline, caused, severe, reser...   \n",
       "13           135458600  loss, small, degradation, red, pollution, low,...   \n",
       "14              170525  however, degradation, mining, long, south, lim...   \n",
       "15               17081  small, declines, decline, red, predation, dest...   \n",
       "16              172524  loss, small, declines, although, decline, red,...   \n",
       "17              173018  illegal, red, low, commercial, conditions, dam...   \n",
       "18              174472  small, although, caused, red, invasive, severe...   \n",
       "19              175363  pressure, restricted, degraded, heavily, cutti...   \n",
       "\n",
       "      Humans Natural  Genes Diseases  \n",
       "Index                                 \n",
       "0       True    True   True     True  \n",
       "1       True    True   True     True  \n",
       "2       True    True   True     True  \n",
       "3       True    True  False     True  \n",
       "4       True    True   True     True  \n",
       "5       True    True  False     True  \n",
       "6       True    True  False     True  \n",
       "7       True    True  False     True  \n",
       "8       True    True  False     True  \n",
       "9       True    True  False     True  \n",
       "10      True    True  False     True  \n",
       "11      True    True   True     True  \n",
       "12      True    True  False     True  \n",
       "13      True    True  False     True  \n",
       "14      True    True  False     True  \n",
       "15      True    True   True     True  \n",
       "16      True    True   True     True  \n",
       "17      True    True  False     True  \n",
       "18      True    True   True     True  \n",
       "19      True    True  False     True  "
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanThreats = pd.read_csv(\"allThreats.csv\")\n",
    "cleanThreats.rename(columns={'Unnamed: 0': 'Index'}, inplace=True)\n",
    "cleanThreats.set_index('Index', drop=True, inplace=True)\n",
    "cleanThreats = cleanThreats[[\"internalTaxonId\", \"Threat Keywords\"]]\n",
    "for index, row in cleanThreats.iterrows():\n",
    "    keyList = str(row['Threat Keywords']).split(\",\")\n",
    "    for s in tcategoryList:\n",
    "        boolean = False\n",
    "        cString = \"\"\n",
    "        if s == humans:\n",
    "            cString = \"Humans\"\n",
    "        if s == natural:\n",
    "            cString = \"Natural\"\n",
    "        if s == genetics:\n",
    "            cString = \"Genes\"\n",
    "        if s == disease:\n",
    "            cString = \"Diseases\"\n",
    "\n",
    "        for k in keyList:\n",
    "            avg = 0\n",
    "            count = 0\n",
    "            temp = wordnet.synsets(k.strip())\n",
    "            for x in temp:\n",
    "                for y in s:\n",
    "                    sim = y.wup_similarity(x)\n",
    "                    if sim > .35:\n",
    "                        avg += sim\n",
    "                        count += 1\n",
    "                        \n",
    "            if count > 0:\n",
    "                avg = avg/count\n",
    "                if avg > .45:\n",
    "                    boolean = True\n",
    "        \n",
    "        cleanThreats.at[index, cString] = boolean\n",
    "\n",
    "cleanThreats.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanThreats.to_csv(\"allThreatsCorrect.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "protection = wordnet.synsets(\"protection\")\n",
    "speciesManagment = wordnet.synsets(\"breeding\")\n",
    "education = wordnet.synsets(\"education\")\n",
    "tradeCtrl = wordnet.synsets(\"trade\")\n",
    "research = wordnet.synsets(\"research\")\n",
    "ccategoryList = [protection, speciesManagment, education, tradeCtrl, research]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanActions = pd.read_csv(\"allConservationActions.csv\")\n",
    "cleanActions.rename(columns={'Unnamed: 0': 'Index'}, inplace=True)\n",
    "cleanActions.set_index('Index', drop=True, inplace=True)\n",
    "cleanActions = cleanActions[[\"internalTaxonId\", \"Conserve Keywords\"]]\n",
    "for index, row in cleanActions.iterrows():\n",
    "    keyList = str(row['Conserve Keywords']).split(\",\")\n",
    "    for s in ccategoryList:\n",
    "        boolean = False\n",
    "        cString = \"\"\n",
    "        if s == protection:\n",
    "            cString = \"land_water_protection\"\n",
    "        if s == speciesManagment:\n",
    "            cString = \"species_management\"\n",
    "        if s == education:\n",
    "            cString = \"education\"\n",
    "        if s == tradeCtrl:\n",
    "            cString = \"trade_control\"\n",
    "        if s == research:\n",
    "            cString = \"research_monitoring\"\n",
    "\n",
    "        for k in keyList:\n",
    "            avg = 0\n",
    "            count = 0\n",
    "            temp = wordnet.synsets(k.strip())\n",
    "            for x in temp:\n",
    "                for y in s:\n",
    "                    sim = y.wup_similarity(x)\n",
    "                    if sim > .30:\n",
    "                        avg += sim\n",
    "                        count += 1\n",
    "                        \n",
    "            if count > 0:\n",
    "                avg = avg/count\n",
    "                if avg > .50:\n",
    "                    boolean = True\n",
    "        \n",
    "        cleanActions.at[index, cString] = boolean\n",
    "\n",
    "cleanActions.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanActions.to_csv(\"allConservationActionsCorrect.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanclean = cleanActions.replace([True, False], [1, 0])\n",
    "cleanclean = pd.concat([cleanclean, dfAssess['assessmentId']], axis=1)\n",
    "cleanclean.reset_index(inplace=True)\n",
    "cleanclean.to_csv(\"conservationActionsCorrect.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "specConserve = cleanclean[['internalTaxonId']]\n",
    "specConserve.reset_index(inplace=True)\n",
    "specConserve.to_csv(\"species_conservation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "specThreats = cleanThreats[['internalTaxonId']]\n",
    "specThreats.reset_index(inplace=True)\n",
    "specThreats.to_csv(\"species_threats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "specHabitats = dfHabitat[['internalTaxonId']]\n",
    "specHabitats.reset_index(inplace=True)\n",
    "specHabitats.to_csv(\"species_habitat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Critically Endangered', 'Endangered', 'Near Threatened', 'Lower Risk/near threatened', 'Vulnerable']\n"
     ]
    }
   ],
   "source": [
    "alist = dfAssessClean['redlistCategory'].to_list()\n",
    "uaList = []\n",
    "for x in alist:\n",
    "    if x not in uaList:\n",
    "        uaList.append(x)\n",
    "print(uaList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAssessC = dfAssessClean.replace(['Critically Endangered', 'Endangered', 'Near Threatened', 'Lower Risk/near threatened', 'Vulnerable'], [0, 1, 2, 3, 4])\n",
    "dfAssessC.to_csv(\"species_assessment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "statusD = {'status_id': [0, 1, 2, 3, 4], 'status_name' : ['Critically Endangered', 'Endangered', 'Near Threatened', 'Lower Risk/near threatened', 'Vulnerable']}\n",
    "statusdf = pd.DataFrame.from_dict(statusD)\n",
    "statusdf.to_csv(\"status.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleancleanT = cleanThreats.replace([True, False], [1, 0])\n",
    "cleancleanT.to_csv(\"threats.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
